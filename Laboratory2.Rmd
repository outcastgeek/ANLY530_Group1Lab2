---
title: "ANLY 530 Group Assignment (Laboratory 2: Naive Bayes Classifiers)"
author:
- "Josseline Betio"
- "Akpany Benjamin Ebby"
- "Yajun Wang"
date: "`r format(Sys.time(), '%d %B %Y')`"
output:
  html_document:
    highlight: zenburn
comment: Rmd Document with Markdown + Embedded R Code
---

---

#### Document as of `r Sys.Date()`

```{r setup, include=FALSE, purl=FALSE, eval=TRUE}

source('R/ANLY530_Laboratory2_Helper.R')

```

```{r echo=FALSE}

library(knitr)
library(kableExtra)
read_chunk('R/ANLY530_Laboratory2_Chunks.R')

```

Some helper functions do exists to support the code snippets below such as: ```fullFilePath```

---

```{r loadLibraries, message=FALSE, warning=FALSE}
```

## Collecting the data

Let us start by [Loading the Data Sheets]

```{r loadSheets, message=FALSE, warning=FALSE}
```

# Credit Data
-------------

# Part 1:

## Step 1: Exploring and Preparing the Data

```{r part1Step1, message=FALSE, warning=FALSE}
```

## Step 2: Training a Model on the Data

```{r part1Step2, message=FALSE, warning=FALSE}
```

## Step 3: Evaluating Model Performance

```{r part1Step3, message=FALSE, warning=FALSE}
```

## Analysis

The credit data set contains 21 variables and 1000 records. Before, applying the naive Bayes to the data set, we prepare the data set. We first ensure that there are no missing values or NA values. The data set is randomized first and then split between a training and test data set.
Also, to use the Naive Bayes classifier we have to make sure to format the class variables as factor. 
After the data preparation, we build the Naive Bayes Classifier model. From the model, it appears 31.4667% of applicants are not credit worthy and 68.5333% of applicants are credit worthy.
To evaluate the model, we use a confusion table. Out of the 250 observations in the testing data set, 193 observations are correctly classified, 57 observations are mis-classified.

---

# Part 2:

## Step 1: Exploring and Preparing the Data

```{r part2Step1, message=FALSE, warning=FALSE}
```

## Step 2: Training a Model on the Data

```{r part2Step2, message=FALSE, warning=FALSE}
```

## Step 3: Evaluating Model Performance

```{r part2Step3, message=FALSE, warning=FALSE}
```

## Analysis


In the second part, we reapply the Naive Bayes Classifier but manually try to improve the model.
Again we prepare analyze the data before applying the model. We scale the randomized data. 
Correlations between variables are analyzed using the corrplot package. We set a correlation threshold as 0.30 and use the "find correlation' function to determine variables that are highly correlated. We observe that account balance, payment status of previous credit, and duration of credit are highly correlated to creditability. Account balance has the highest correlation with creditability. Account balance and payment status of previous credit are positively correlated to creditability while duration of credit is negatively correlated to creditability.
We apply the Naive Bayes model to the filtered data and evaluate the model on the test data set. Out of 250 observations, 186 observations are correctly classified. The accuracy level is at 74.4% which is lower compared to the accuracy level in part 1.



# ONLINE NEWS POPULARITY
------------------------

# Part 3:

## Step 1: Exploring and Preparing the Data

```{r part3Step1, message=FALSE, warning=FALSE}
```

## Step 2: Training a Model on the Data

```{r part3Step2, message=FALSE, warning=FALSE}
```

## Step 3: Evaluating Model Performance

```{r part3Step3, message=FALSE, warning=FALSE}
```

## Analysis

n part 3 we applied the two previous methods to the online news popularity data set. We prepare the data by converting the news popularity variable into a factor variable and split the data set into a training and test data set again. The first method with no manual improvement classifies all observations correctly and has an accuracy rate of 100%.
Therefore, we recommend using the first method since in the previous parts, it also generated a higher accuracy rate.
